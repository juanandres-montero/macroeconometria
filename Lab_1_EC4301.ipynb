{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10efdb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://github.com/juanandres-montero/macroeconometria/blob/main/logo%20EEC%20grande.png?raw=true" width=\"396\" height=\"161\"><br>\n",
    "    <b>EC4301 MACROECONOMETRÍA</b><br>\n",
    "    <b>Asist: Juan Andrés Montero Zúñiga</b>\n",
    "<br><br>\n",
    "<b> Laboratorio #1:</b>\n",
    "<br>    \n",
    "<div style=\"font-size:250%; color:white; background-color: #0064b0; padding-top: 20px; padding-bottom: 20px; width: 50%; margin: 0 auto; border-radius: 15px;\">\n",
    "    Máxima Verosimilitud\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<i> \n",
    "    Creado: Agosto 2024\n",
    "</i>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8a7fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cobb-Douglas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b19dc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Se tiene una función de producción ($Q_i$) dependiente de trabajo ($L_i$) y capital ($K_i$) de la forma Cobb-Douglas asumiendo un error multiplicativo log-normal y homocedástico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46dd302",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$Q_i = \\beta_0 L_i^{\\beta_1}K_i^{\\beta_2}\\epsilon_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d4893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Repaso distribución log-normal\n",
    "Se tiene una media (m) y una varianza (v):\n",
    "$$\n",
    "m = \\exp\\left(\\mu + \\frac{\\sigma^2}{2}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "v = \\exp\\left(2\\mu + \\sigma^2\\right)\\left(\\exp\\left(\\sigma^2\\right) - 1\\right)\n",
    "$$\n",
    "Puede calcular los parámetros de distribución lognormal µ y σ a partir de la media m y la varianza v:\n",
    "$$\n",
    "\\mu = \\log\\left(\\frac{m^2}{\\sqrt{v + m^2}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\log\\left(\\frac{v}{m^2} + 1\\right)}\n",
    "$$\n",
    "### Función de densidad de probabilidad\n",
    "$$\n",
    "y = f(x \\mid \\mu, \\sigma) = \\frac{1}{x\\sigma\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{(\\log x - \\mu)^2}{2\\sigma^2}\\right\\}, \\quad \\text{for } x > 0.\n",
    "$$\n",
    "\n",
    "Fuente: [MATLAB](https://es.mathworks.com/help/stats/lognormal-distribution.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ff2b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Máxima Verosimilitud en STATA\n",
    "En nuestro caso $\\epsilon_i \\sim \\text{LN}(0, \\sigma ^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3438a6",
   "metadata": {},
   "source": [
    "En STATA crearemos el programa \"**cobbdouglas_mv**\", definimos su versión, y los \"**args**\" a usar, en este caso:\n",
    "- \"**lnf**\" indica que es una función de logverosimilitud $\\ln(\\beta_0) + \\beta_1 \\ln(L_i) + \\beta_2 \\ln(K_i)$\n",
    "- \"**mu**\" puede tener otro nombre, en este momento señala que la combinación especificada es la media.\n",
    "- \"**sigma**\" es la desviación estándar del error.\n",
    "\n",
    "Finalmente, se plantea la relación que van a tener los argumentos. Ahora se calcula el logaritmo de las variables y se plantea el modelo con **ml**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4ed83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimar el modelo\n",
    "\n",
    "En **ml model** se especifica el modelo, **lf** especifica que el contexto es de forma lineal, luego se definen las variables y un paréntesis vacío indicando error homocedástico. Ahora, con **ml max** se estima el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436452e7",
   "metadata": {},
   "source": [
    "En los resultados se obtienen los coeficientes (Betas) en la sección **eq1**. En **eq2** se obtiene la varianza ($\\sigma^2$) del error $\\epsilon_i$. Note que los coeficientes de trabajo y capital no suman 1 y podemos plantear la hipótesis nula de que la función de producción presenta rendimientos constantes a escala con la prueba de *razón de verosimilitud*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523534b",
   "metadata": {},
   "source": [
    "Para esto se impone una restricción con el comando **constraint** señalando que la suma de los coeficientes es igual a 1. En ambos modelos se guardan los resultados bajo los nombres **m1** y **m2**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b208c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Testeando los resultados\n",
    "\n",
    "#### Razón de verosimilitud\n",
    "\n",
    "Simplemente debemos correr **lrtest m1 m2**. Con un p-value muy bajo rechazamos la hipótesis nula de rendimientos constantes a escala a todos los niveles de significancia. \n",
    "\n",
    "### Wald\n",
    "\n",
    "Se llega al mismo resultado con un simple **test** que compare los resultados del modelo sin restricción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb313e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://github.com/juanandres-montero/macroeconometria/blob/main/image.png?raw=true\" width=\"396\" height=\"161\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceee184",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Especificación del Modelo con Error Aditivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dac9b5",
   "metadata": {},
   "source": [
    "En el modelo anterior el término error multiplica a la regresión, esto puede no ser del todo apropiado porque asume que la variabilidad o el \"ruido\" en los datos es proporcional al valor de la regresión. Ahora se plantea lo siguiente: $$Q_i = \\beta_0 L_i^{\\beta_1} K_i^{\\beta_2} + \\epsilon_i \\quad \\text{con} \\quad \\epsilon_i \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "Despejando el error se tiene:\n",
    "$$\\epsilon_i = Q_i - \\beta_0 L_i^{\\beta_1} K_i^{\\beta_2} = Q_i - \\beta_0 \\exp\\left\\{\\beta_1 \\ln(L_i) + \\beta_2 \\ln(K_i)\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aadfebd",
   "metadata": {},
   "source": [
    "El proceso es muy similar, se crea un programa nuevo, indica versión y sus **args**, lo diferente es que ahora se agrega el factor tecnología **b0** y los demas factores ponderados **b1x**, note que los residuos (**res**) son iguales a la diferencia de la regresión y estos residuos se distribuyen de manera normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777ee34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Repaso distribución normal\n",
    "Los estimadores de máxima verosimilitud de μ y σ2 para la distribución normal, respectivamente, son:\n",
    "$$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$\n",
    "$$s^2_{\\text{MLE}} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2.$$\n",
    "$$s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2, \\quad\\text{(insesgado)}$$ \n",
    "### Función de densidad de probabilidad\n",
    "$$y = f(x \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}, \\quad \\text{para } x \\in \\mathbb{R}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f607d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Log-Verosimilitud\n",
    "La log-verosimilitud, $\\ln L$, es el logaritmo natural de la función de verosimilitud. Para $n$ observaciones independientes, la log-verosimilitud de los datos bajo este modelo normal es la suma de los logaritmos de las densidades de probabilidad:\n",
    "\n",
    "$$\n",
    "\\ln L(\\mu, \\sigma) = \\sum_{i=1}^{n} \\ln\\left(\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2 \\sigma^2}\\right)\\right)\n",
    "$$\n",
    "\n",
    "Desglosando esta expresión:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n}\\ln\\left(\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\right) + \\sum_{i=1}^{n}\\left(-\\frac{(x_i - \\mu_i)^2}{2 \\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\sum_{i=1}^{n}(\\ln(1) - \\ln(\\sqrt{2 \\pi \\sigma^2})) = -\\frac{n}{2} \\ln({2 \\pi}) - n \\ln(\\sigma)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore\\ln L(\\mu, \\sigma^2) = -\\frac{n}{2} \\ln({2 \\pi}) - n \\ln(\\sigma) - \\frac{1}{2 \\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fba7db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Caso un único error $$\\epsilon \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "$$f(e) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{\\epsilon^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "$$\\ln L = \\ln\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{\\epsilon^2}{2\\sigma^2}\\right)\\right)$$\n",
    "\n",
    "$$\\ln L = \\ln\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\right) - \\frac{\\epsilon^2}{2\\sigma^2}$$\n",
    "\n",
    "Por lo tanto, la función de log-verosimilitud completa se convierte en:\n",
    "\n",
    "$$\n",
    "\\ln L = -\\frac{1}{2}\\ln(2\\pi) - \\ln(\\sigma) - \\frac{\\epsilon^2}{2\\sigma^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c24019",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esta función permitirá comparar diferentes funciones **log-likelihood** en STATA, por lo tanto las incluimos en el **program** de la forma:\n",
    "\n",
    "```-0.5*ln(2*_pi)-ln(`sigma')-0.5*`res'^2/`sigma^2'```\n",
    "\n",
    "Finalmente ejecutamos el modelo \"maximum likelihood\" **ml model lf cobbdouglas2 (b1: Q=ln_L ln_K, nocons) (b0:) (sigma:)** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e83fcb",
   "metadata": {},
   "source": [
    "Finalmente realizamos los mismos tests que en modelo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0340595",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ejemplo de estimación de máxima verosimilitud a mano\n",
    "\n",
    "FDP exponencial:\n",
    "$$y = f(x \\mid \\theta) = \\frac{1}{\\theta} e^{-\\frac{x}{\\theta}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130f87a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paso 1: Multiplicatoria\n",
    "La función de verosimilitud $L(\\theta)$ para una muestra de tamaño $n$ es el producto de las funciones de densidad individuales:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{n} f(x_i \\mid \\theta) = \\prod_{i=1}^{n} \\frac{1}{\\theta} e^{-\\frac{x_i}{\\theta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701b7b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paso 2: Log-Verosimilitud\n",
    "\n",
    "Tomamos el logaritmo natural de la función de verosimilitud para obtener la función de log-verosimilitud \\( \\ell(\\theta) \\):\n",
    "\n",
    "$$\n",
    "\\ell(\\theta) = \\ln L(\\theta) = \\ln \\left( \\prod_{i=1}^{n} \\frac{1}{\\theta} e^{-\\frac{x_i}{\\theta}} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\ell(\\theta) = -n \\ln \\theta - \\frac{1}{\\theta} \\sum_{i=1}^{n} x_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b61d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paso 3: Derivada de la Log-Verosimilitud\n",
    "\n",
    "Para encontrar el MLE, derivamos $\\ell(\\theta)$ con respecto a $\\theta$ e igualamos a cero:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell(\\theta)}{\\partial \\theta} = -\\frac{n}{\\theta} + \\frac{1}{\\theta^2} \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell(\\theta)}{\\partial \\theta} = 0 \\implies -\\frac{n}{\\theta} + \\frac{1}{\\theta^2} \\sum_{i=1}^{n} x_i = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be49bbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paso 4: Resolución para el Estimador de Máxima Verosimilitud\n",
    "\n",
    "Resolviendo la ecuación anterior para $\\theta$:\n",
    "\n",
    "$$\n",
    "-\\frac{n}{\\theta} + \\frac{1}{\\theta^2} \\sum_{i=1}^{n} x_i = 0\n",
    "$$\n",
    "\n",
    "Multiplicamos ambos lados por $\\theta^2$:\n",
    "\n",
    "$$\n",
    "-n \\theta + \\sum_{i=1}^{n} x_i = 0\n",
    "$$\n",
    "\n",
    "Por lo tanto, el estimador de máxima verosimilitud para $\\theta$ es:\n",
    "$$\n",
    "\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\bar x\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
